{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JM-AXvmCp_q1",
        "outputId": "4671a228-abac-4117-8b86-39716b5bfbfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.17)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.6)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.2.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.2.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.10)\n",
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n",
            "Dataset URL: https://www.kaggle.com/datasets/asupreethgupta/sandalwood-kanada\n",
            "License(s): unknown\n",
            "Downloading sandalwood-kanada.zip to /content\n",
            " 99% 624M/629M [00:04<00:00, 151MB/s]\n",
            "100% 629M/629M [00:04<00:00, 152MB/s]\n",
            "Archive:  sandalwood-kanada.zip\n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_1.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_107.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_112.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_144.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_146.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_148.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_156.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_158.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_159.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_167.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_168.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_169.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_171.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_172.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_173.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_174.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_175.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_176.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_179.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_181.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_184.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_191.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_197.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_2.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_200.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_211.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_215.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_223.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_229.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_23.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_230.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_239.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_242.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_249.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_257.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_278.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_279.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_280.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_282.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_283.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_284.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_286.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_287.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_291.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_294.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_295.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_296.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_297.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_298.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_299.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_303.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_304.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_305.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_306.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_33.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_35.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_36.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_41.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_42.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_43.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_45.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_46.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_52.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_53.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_6.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_63.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_89.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_9.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_98.mp3  \n",
            "  inflating: /content/sandalwood_dataset/SandalWoodNewsStories_99.mp3  \n"
          ]
        }
      ],
      "source": [
        "# Install Kaggle CLI\n",
        "!pip install kaggle\n",
        "\n",
        "import os\n",
        "os.makedirs(\"/root/.kaggle/\", exist_ok=True)\n",
        "\n",
        "# Move kaggle.json to the correct directory\n",
        "import shutil\n",
        "shutil.move(\"kaggle.json\", \"/root/.kaggle/\")\n",
        "\n",
        "# Download the dataset\n",
        "!kaggle datasets download -d asupreethgupta/sandalwood-kanada\n",
        "\n",
        "# Unzip the dataset\n",
        "!unzip sandalwood-kanada.zip -d /content/sandalwood_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pCUE8ts4p_q2"
      },
      "outputs": [],
      "source": [
        "# !huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0pjDyePp_q6"
      },
      "outputs": [],
      "source": [
        "# !pip uninstall -y tensorflow\n",
        "# !pip install tensorflow-cpu\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TaZ0hR_NkpMl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor, pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import sqlite3\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import soundfile as sf\n",
        "from typing import List, Dict\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.ERROR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXc_L8RDy4jU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(\"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\")\n"
      ],
      "metadata": {
        "id": "QryQntCjOfh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1QhASxGG6qu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ab45c1-5e58-4b70-e266-b4294a11eb22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py:306: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribed Question: ಗಂದ ಮರ ಅಂದರೆಯನು\n",
            "\n",
            "ಉತ್ತರಗಳು:\n",
            "ಉತ್ತರ: ಅದು ತಾಂತನ ಬಲ್ಲಗೈಗೀತರೆ, ನಂಬಿಕೆ: 0.03, ಮೂಲ ಫೈಲ್: SandalWoodNewsStories_287.mp3, ಚಂಕ್ ಸೂಚ್ಯಂಕ: 4\n",
            "ಉತ್ತರ: ನೂಮೂರು ಸಾೈಗಿ ಪೂರಜಮೂರುರಸೆ, ನಂಬಿಕೆ: 0.08, ಮೂಲ ಫೈಲ್: SandalWoodNewsStories_287.mp3, ಚಂಕ್ ಸೂಚ್ಯಂಕ: 22\n",
            "ಉತ್ತರ: ಒಂದ ಒಲ್ಲಕ್ಷ್ ಮಟ್ಟೆಗ್ಳೂ, ನಂಬಿಕೆ: 0.06, ಮೂಲ ಫೈಲ್: SandalWoodNewsStories_287.mp3, ಚಂಕ್ ಸೂಚ್ಯಂಕ: 29\n",
            "ಉತ್ತರ: ನುದುಮಣ್ಯತ್ತು ಗಿಳದಪ್ಪಾಗ್ಗಿತ್ತ, ನಂಬಿಕೆ: 0.02, ಮೂಲ ಫೈಲ್: SandalWoodNewsStories_287.mp3, ಚಂಕ್ ಸೂಚ್ಯಂಕ: 42\n",
            "ಉತ್ತರ: ದ್ರೆ ಸ್ರಿಗಾಂದವಿಗಳ ಹಿನಾರವರ್ಷಿತಕ, ನಂಬಿಕೆ: 0.03, ಮೂಲ ಫೈಲ್: SandalWoodNewsStories_287.mp3, ಚಂಕ್ ಸೂಚ್ಯಂಕ: 59\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from transformers import pipeline, Wav2Vec2Processor, Wav2Vec2ForCTC\n",
        "\n",
        "\n",
        "class KannadaSpeechQA:\n",
        "    def __init__(self, transcription_csv: str, device: str = None):\n",
        "        self.transcription_csv = transcription_csv\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.processor = Wav2Vec2Processor.from_pretrained(\"amoghsgopadi/wav2vec2-large-xlsr-kn\")\n",
        "        self.transcriber_model = Wav2Vec2ForCTC.from_pretrained(\"amoghsgopadi/wav2vec2-large-xlsr-kn\").to(self.device)\n",
        "        self.embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
        "        self.qa_model = pipeline(\"question-answering\", model=\"Sindhu/muril-large-squad2\")\n",
        "\n",
        "        # Load transcriptions from CSV\n",
        "        self.transcriptions = pd.read_csv(self.transcription_csv, encoding=\"utf-8\")\n",
        "\n",
        "    def transcribe_audio(self, audio_path: str) -> str:\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "        if waveform.shape[0] > 1:  # Convert stereo to mono\n",
        "            waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "        if sample_rate != 16000:  # Resample to 16kHz\n",
        "            resampler = torchaudio.transforms.Resample(sample_rate, 16000)\n",
        "            waveform = resampler(waveform)\n",
        "        inputs = self.processor(waveform.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\", padding=True).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            logits = self.transcriber_model(inputs.input_values).logits\n",
        "        predicted_ids = torch.argmax(logits, dim=-1)\n",
        "        transcription = self.processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "        print(f\"Transcribed Question: {transcription}\")\n",
        "        return transcription\n",
        "\n",
        "    def search_answers(self, question: str, top_k: int = 5) -> list:\n",
        "        question_embedding = self.embedding_model.encode(question)\n",
        "\n",
        "        results = []\n",
        "        for _, row in self.transcriptions.iterrows():\n",
        "            context = str(row[\"Transcription\"])\n",
        "            context_embedding = self.embedding_model.encode(context)\n",
        "            similarity = cosine_similarity(\n",
        "                question_embedding.reshape(1, -1),\n",
        "                context_embedding.reshape(1, -1)\n",
        "            )[0][0]\n",
        "            results.append({\n",
        "                \"file\": row[\"File\"],\n",
        "                \"chunk_index\": row[\"Chunk_Index\"],\n",
        "                \"transcription\": context,\n",
        "                \"similarity\": similarity,\n",
        "            })\n",
        "\n",
        "        # Sort results by similarity\n",
        "        sorted_results = sorted(results, key=lambda x: x[\"similarity\"], reverse=True)[:top_k]\n",
        "\n",
        "        answers = []\n",
        "        for result in sorted_results:\n",
        "            qa_result = self.qa_model(question=question, context=result[\"transcription\"])\n",
        "            answers.append({\n",
        "                \"answer\": qa_result[\"answer\"],\n",
        "                \"confidence\": qa_result[\"score\"],\n",
        "                \"source_file\": result[\"file\"],\n",
        "                \"chunk_index\": result[\"chunk_index\"],\n",
        "                \"context\": result[\"transcription\"],\n",
        "            })\n",
        "        return answers\n",
        "\n",
        "    def answer_question(self, question_audio_path: str):\n",
        "        # Transcribe the question audio\n",
        "        question_text = self.transcribe_audio(question_audio_path)\n",
        "\n",
        "        # Search for answers\n",
        "        answers = self.search_answers(question_text)\n",
        "\n",
        "        # Print answers in Kannada\n",
        "        print(\"\\nಉತ್ತರಗಳು:\")\n",
        "        for ans in answers:\n",
        "            print(f\"ಉತ್ತರ: {ans['answer']}, ನಂಬಿಕೆ: {ans['confidence']:.2f}, ಮೂಲ ಫೈಲ್: {ans['source_file']}, ಚಂಕ್ ಸೂಚ್ಯಂಕ: {ans['chunk_index']}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    transcription_csv = \"/content/kannada_transcriptions.csv\"\n",
        "    question_audio_path = \"/content/queation.mp3\"\n",
        "\n",
        "    qa_system = KannadaSpeechQA(transcription_csv=transcription_csv)\n",
        "    qa_system.answer_question(question_audio_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def normalize_answer(s):\n",
        "    \"\"\"Normalize text to remove articles, punctuation, and whitespace.\"\"\"\n",
        "    s = s.lower()\n",
        "    s = re.sub(r'\\b(a|an|the)\\b', ' ', s)  # Remove articles\n",
        "    s = re.sub(r'[^a-zA-Z0-9\\u0C80-\\u0CFF]', ' ', s)  # Keep Kannada and alphanumeric\n",
        "    s = ' '.join(s.split())  # Remove extra whitespace\n",
        "    return s\n",
        "\n",
        "def compute_exact_match(predicted_answers, ground_truth_answers):\n",
        "    \"\"\"Compute Exact Match (EM) score.\"\"\"\n",
        "    exact_matches = 0\n",
        "    for pred, gt in zip(predicted_answers, ground_truth_answers):\n",
        "        if normalize_answer(pred) == normalize_answer(gt):\n",
        "            exact_matches += 1\n",
        "    return exact_matches / len(ground_truth_answers) * 100\n",
        "\n",
        "def compute_f1(predicted_answers, ground_truth_answers):\n",
        "    \"\"\"Compute F1 Score.\"\"\"\n",
        "    f1_scores = []\n",
        "    for pred, gt in zip(predicted_answers, ground_truth_answers):\n",
        "        pred_tokens = normalize_answer(pred).split()\n",
        "        gt_tokens = normalize_answer(gt).split()\n",
        "\n",
        "        common_tokens = set(pred_tokens) & set(gt_tokens)\n",
        "        if not common_tokens:\n",
        "            f1_scores.append(0)\n",
        "            continue\n",
        "\n",
        "        precision = len(common_tokens) / len(pred_tokens)\n",
        "        recall = len(common_tokens) / len(gt_tokens)\n",
        "        f1 = 2 * (precision * recall) / (precision + recall)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    return sum(f1_scores) / len(f1_scores) * 100\n",
        "\n",
        "def evaluate(predicted_answers, ground_truth_answers):\n",
        "    \"\"\"Evaluate predictions with Exact Match and F1 metrics.\"\"\"\n",
        "    em_score = compute_exact_match(predicted_answers, ground_truth_answers)\n",
        "    f1_score_value = compute_f1(predicted_answers, ground_truth_answers)\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    print(\"📊 Evaluation Metrics\".center(50))\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"🔍 Exact Match (EM): {em_score:.2f}%\")\n",
        "    print(f\"🏆 F1 Score: {f1_score_value:.2f}%\")\n",
        "    print(\"=\" * 50)\n",
        "    print(f\"{'Prediction':<30} | {'Ground Truth':<30} | {'Match'}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    for pred, gt in zip(predicted_answers, ground_truth_answers):\n",
        "        normalized_pred = normalize_answer(pred)\n",
        "        normalized_gt = normalize_answer(gt)\n",
        "        match = \"✅\" if normalized_pred == normalized_gt else \"❌\"\n",
        "        print(f\"{pred:<30} | {gt:<30} | {match}\")\n",
        "\n",
        "    print(\"=\" * 50)\n",
        "    return em_score, f1_score_value\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample predicted answers and ground truth answers\n",
        "    predicted_answers = [\n",
        "        \"ಕಳೆದ ವಾರದ ವರದಿ\",\n",
        "        \"ನಿಮ್ಮ ಕೋಡ್ ಉತ್ತಮವಾಗಿದೆ\",\n",
        "        \"ಅವರು ಸಂಜೆ ಬಂದು ಹೋಗಿದ್ದರು\",\n",
        "        \"ಶಿಕ್ಷಕರ ಸಭೆ ಸೋಮವಾರ ನಡೆಯಿತು\",\n",
        "        \"ನಿಮ್ಮ ಹಾಲು ತಿನ್ನುವ ಬಗ್ಗೆಯೆನ್ನಿಸುತ್ತಿದೆ\",\n",
        "        \"ಅವರು ನನಗೆ ಟಿಕೆಟ್ ನೀಡಿದರು\",\n",
        "        \"ಪ್ರಯಾಣ ಉತ್ತಮವಾಗಿತ್ತು\",\n",
        "        \"ಅವರು ಮನೆಯಲ್ಲಿಲ್ಲ\",\n",
        "        \"ನಿಮ್ಮ ಯೋಜನೆ ತತ್ತ್ವಾತ್ಮಕವಾಗಿದೆ\",\n",
        "        \"ನಾನು ಪುಸ್ತಕವನ್ನು ಓದಿದೆ\"\n",
        "    ]\n",
        "\n",
        "    ground_truth_answers = [\n",
        "        \"ಕಳೆದ ವಾರದ ವರದಿ\",\n",
        "        \"ನಿಮ್ಮ ಕೋಡ್ ಉತ್ತಮವಾಗಿದೆ\",\n",
        "        \"ಅವರು ಸಂಜೆ ಬಂದಿದ್ದರು\",\n",
        "        \"ಶಿಕ್ಷಕರ ಸಭೆ ಸೋಮವಾರ ನಡೆಯಿತು\",\n",
        "        \"ನಿಮ್ಮ ಹಾಲು ತಿನ್ನುವ ಬಗ್ಗೆ ಪ್ರಶ್ನೆ ಕೇಳಿದ್ದರು\",\n",
        "        \"ಅವರು ನನಗೆ ಟಿಕೆಟ್ ಕೊಟ್ಟರು\",\n",
        "        \"ಪ್ರಯಾಣ ಉತ್ತಮವಾಗಿತ್ತು\",\n",
        "        \"ಅವರು ಮನೆಯಲ್ಲಿಲ್ಲ\",\n",
        "        \"ನಿಮ್ಮ ಯೋಜನೆ ತತ್ತ್ವಾತ್ಮಕವಾಗಿದೆ\",\n",
        "        \"ನಾನು ಪುಸ್ತಕ ಓದಿದ್ದೇನೆ\"\n",
        "    ]\n",
        "\n",
        "    # Evaluate\n",
        "    evaluate(predicted_answers, ground_truth_answers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b018n0HKOOQ4",
        "outputId": "0fe17860-bb76-4028-dc93-f6005301bb8f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "               📊 Evaluation Metrics               \n",
            "==================================================\n",
            "🔍 Exact Match (EM): 60.00%\n",
            "🏆 F1 Score: 82.55%\n",
            "==================================================\n",
            "Prediction                     | Ground Truth                   | Match\n",
            "--------------------------------------------------\n",
            "ಕಳೆದ ವಾರದ ವರದಿ                 | ಕಳೆದ ವಾರದ ವರದಿ                 | ✅\n",
            "ನಿಮ್ಮ ಕೋಡ್ ಉತ್ತಮವಾಗಿದೆ         | ನಿಮ್ಮ ಕೋಡ್ ಉತ್ತಮವಾಗಿದೆ         | ✅\n",
            "ಅವರು ಸಂಜೆ ಬಂದು ಹೋಗಿದ್ದರು       | ಅವರು ಸಂಜೆ ಬಂದಿದ್ದರು            | ❌\n",
            "ಶಿಕ್ಷಕರ ಸಭೆ ಸೋಮವಾರ ನಡೆಯಿತು     | ಶಿಕ್ಷಕರ ಸಭೆ ಸೋಮವಾರ ನಡೆಯಿತು     | ✅\n",
            "ನಿಮ್ಮ ಹಾಲು ತಿನ್ನುವ ಬಗ್ಗೆಯೆನ್ನಿಸುತ್ತಿದೆ | ನಿಮ್ಮ ಹಾಲು ತಿನ್ನುವ ಬಗ್ಗೆ ಪ್ರಶ್ನೆ ಕೇಳಿದ್ದರು | ❌\n",
            "ಅವರು ನನಗೆ ಟಿಕೆಟ್ ನೀಡಿದರು       | ಅವರು ನನಗೆ ಟಿಕೆಟ್ ಕೊಟ್ಟರು       | ❌\n",
            "ಪ್ರಯಾಣ ಉತ್ತಮವಾಗಿತ್ತು           | ಪ್ರಯಾಣ ಉತ್ತಮವಾಗಿತ್ತು           | ✅\n",
            "ಅವರು ಮನೆಯಲ್ಲಿಲ್ಲ               | ಅವರು ಮನೆಯಲ್ಲಿಲ್ಲ               | ✅\n",
            "ನಿಮ್ಮ ಯೋಜನೆ ತತ್ತ್ವಾತ್ಮಕವಾಗಿದೆ  | ನಿಮ್ಮ ಯೋಜನೆ ತತ್ತ್ವಾತ್ಮಕವಾಗಿದೆ  | ✅\n",
            "ನಾನು ಪುಸ್ತಕವನ್ನು ಓದಿದೆ         | ನಾನು ಪುಸ್ತಕ ಓದಿದ್ದೇನೆ          | ❌\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from jiwer import wer\n",
        "\n",
        "def calculate_wer(predicted_answers, ground_truth_answers):\n",
        "    \"\"\"\n",
        "    Calculate the Word Error Rate (WER) for a set of predicted answers and ground truth answers.\n",
        "\n",
        "    Args:\n",
        "        predicted_answers (list of str): List of predicted answers.\n",
        "        ground_truth_answers (list of str): List of ground truth answers.\n",
        "\n",
        "    Returns:\n",
        "        float: Average WER across all samples.\n",
        "    \"\"\"\n",
        "    total_wer = []\n",
        "    for pred, gt in zip(predicted_answers, ground_truth_answers):\n",
        "        # Calculate WER for each pair\n",
        "        error = wer(gt, pred)\n",
        "        print(f\"Ground Truth: {gt}\")\n",
        "        print(f\"Predicted: {pred}\")\n",
        "        print(f\"WER: {error:.2f}\")\n",
        "        total_wer.append(error)\n",
        "\n",
        "    # Average WER across all samples\n",
        "    avg_wer = np.mean(total_wer)\n",
        "    print(f\"\\nAverage WER: {avg_wer:.2f}\")\n",
        "    return avg_wer\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample predicted answers and ground truth answers\n",
        "    predicted_answers = [\n",
        "        \"ಕಳೆದ ವಾರದ ವರದಿ\",\n",
        "        \"ನಿಮ್ಮ ಕೋಡ್ ಉತ್ತಮವಾಗಿದೆ\",\n",
        "        \"ಅವರು ಸಂಜೆ ಬಂದು ಹೋಗಿದ್ದರು\",\n",
        "        \"ಶಿಕ್ಷಕರ ಸಭೆ ಸೋಮವಾರ ನಡೆಯಿತು\",\n",
        "        \"ನಿಮ್ಮ ಹಾಲು ತಿನ್ನುವ ಬಗ್ಗೆಯೆನ್ನಿಸುತ್ತದೆ\",\n",
        "    ]\n",
        "\n",
        "    ground_truth_answers = [\n",
        "        \"ಕಳೆದ ವಾರದ ವರದಿ\",\n",
        "        \"ನಿಮ್ಮ ಕೋಡ್ ಉತ್ತಮವಾಗಿದೆ\",\n",
        "        \"ಅವರು ಸಂಜೆ ಬಂದಿದ್ದರು\",\n",
        "        \"ಶಿಕ್ಷಕರ ಸಭೆ ಸೋಮವಾರ ನಡೆಯಿತು\",\n",
        "        \"ನಿಮ್ಮ ಹಾಲು ತಿನ್ನುವ ಬಗ್ಗೆ ಪ್ರಶ್ನೆ ಕೇಳಿದರು\",\n",
        "    ]\n",
        "\n",
        "    calculate_wer(predicted_answers, ground_truth_answers)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tignHfofqM7",
        "outputId": "5cc8ead3-8d4a-4334-fc11-a28da87a9705"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ground Truth: ಕಳೆದ ವಾರದ ವರದಿ\n",
            "Predicted: ಕಳೆದ ವಾರದ ವರದಿ\n",
            "WER: 0.00\n",
            "Ground Truth: ನಿಮ್ಮ ಕೋಡ್ ಉತ್ತಮವಾಗಿದೆ\n",
            "Predicted: ನಿಮ್ಮ ಕೋಡ್ ಉತ್ತಮವಾಗಿದೆ\n",
            "WER: 0.00\n",
            "Ground Truth: ಅವರು ಸಂಜೆ ಬಂದಿದ್ದರು\n",
            "Predicted: ಅವರು ಸಂಜೆ ಬಂದು ಹೋಗಿದ್ದರು\n",
            "WER: 0.67\n",
            "Ground Truth: ಶಿಕ್ಷಕರ ಸಭೆ ಸೋಮವಾರ ನಡೆಯಿತು\n",
            "Predicted: ಶಿಕ್ಷಕರ ಸಭೆ ಸೋಮವಾರ ನಡೆಯಿತು\n",
            "WER: 0.00\n",
            "Ground Truth: ನಿಮ್ಮ ಹಾಲು ತಿನ್ನುವ ಬಗ್ಗೆ ಪ್ರಶ್ನೆ ಕೇಳಿದರು\n",
            "Predicted: ನಿಮ್ಮ ಹಾಲು ತಿನ್ನುವ ಬಗ್ಗೆಯೆನ್ನಿಸುತ್ತದೆ\n",
            "WER: 0.50\n",
            "\n",
            "Average WER: 0.23\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "heGMwc9ehNg3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 6079877,
          "sourceId": 9897948,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30786,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}